\documentclass[twoside, 11pt]{article}

\usepackage{jmlr2e}

\usepackage{amsmath}
\usepackage{amsfonts}

\newcommand{\xx}[0] {\mathbb{X}} % decision variable space
\newcommand{\hh}[0] {\mathbb{H}} % stochastic process for state
\newcommand{\zz}[0] {\mathbb{Z}} % hidden event space?
\newcommand{\mm}[0] {\mathbb{M}} % HMM model type space
\newcommand{\TT}[0] {\mathbb{T}} % time indices
\newcommand{\II}[0] {\mathbb{I}} % factorial model indices
\newcommand{\traj}[1] {H^{(#1)}}
\newcommand{\state}[2] {H_{#2}^{(#1)}}
\newcommand{\event}[2] {Z_{#2}^{(#1)}}
\newcommand{\eventseq}[1] {Z_{(#1)}}
\newcommand{\reals}[0] {\mathbb{R}}
\newcommand{\naturals}[0] {\mathbb{N}}
\newcommand{\events}[0] {\mathbb{Y}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}

\author{\name Reuben Fletcher-Costin}

\editor{}

\title{Approximate MAP inference of sparse factorial hidden Markov models through set cover decomposition}

\maketitle

\begin{abstract}%
Our goal is to infer a sparse subset of hidden Markov models (HMMs) that collectively explain a sequence of observations. We define a probabilistic model for a simple form of factorial HMMs and pose a maximum a posteriori (MAP) estimation problem to infer a sparse subset of component HMM, their hidden states, and separate the observations into component signals associated with each component HMM. We show that the MAP estimation problem is equivalent to an exact cover problem, where each component HMM is regarded as a set that covers a portion of the observed signal. This permits a relaxed approximation of the problem to be decomposed as a master set cover problem and auxiliary problem using column generation. Each auxiliary problem can be solved efficiently using dynamic programming by a "prize-collecting" modified Viterbi algorithm that recovers a HMM trajectory that incorporates prizes from the master problem for explaining portions of the observed signal.
\end{abstract}

% keywords could go here

\section{Introduction}

Todo.

\begin{itemize}

\item why anyone might care about HMMs

\item separation problems, why anyone might care about those

\item HMMs

\item Factorial HMMs

\item alternatives to HMMs

\item linear programming and convex optimisation decompositions

\end{itemize}

\section{Probabilistic model}

\subsection{Hidden Markov models}
We start by assuming a family of hidden Markov models, indexed by $m \in \mm$. Each model $m \in \mm$ in the family has a finite state space $S_m$ consisting of $K_m \in \naturals$ states $\{s_1, \ldots, s_{K_m}\}$. The state of the model $m$ at time $t \in \TT = \{ 1, \ldots, T \}$ is denoted by the random variable $H_{m, t}$ which takes values in the state space $S_m$. We regard the states as not directly observable and will often refer to them as hidden (aka latent) states. The hidden states of model $m$ evolve in time independently from other models according to a discrete time first-order Markov process
\begin{equation}
P(H_{m,t+1} \mid \{ H_{m^{\prime},t^{\prime}} \}_{m^{\prime}, t^{\prime} \in \mm \times \TT \setminus \{m, t\}} )
=
P(H_{m,t+1} \mid H_{m,t} )
\end{equation}
We assume that the transition model $P(H_{m,t+1} \mid H_{m,t} )$ for each $m \in \mm$ is stationary, that is, there exists some stochastic matrix $A^{m}$ with elements $A^{m}_{s^{\prime}, s} = P(H_{m, t+1}=s^{\prime} \mid H_{m,t}=s)$. We write $\pi_m$ to denote a prior distribution over $H_{m,1}$ at $t=1$.

Each hidden Markov model $m$ emits a sequence of events $Z_{m,1}, \ldots, Z_{m,T}$, where each $Z_{m,t} \in \events$. The space of events $\events$ is assumed to be a vector space over $\reals$. Each $Z_{m,t}$ is assumed to be caused solely by the corresponding hidden state $H_{m,t}$:
\begin{equation}
P\left(Z_{m,t}
\mid
\{ H_{m^{\prime},t^{\prime}} \}_{m^{\prime}, t^{\prime} \in \mm \times \TT} \;
\{ Z_{m^{\prime},t^{\prime}} \}_{m^{\prime}, t^{\prime} \in \mm \times \TT \setminus \{m, t\}}
\right)
=
P(Z_{m,t} \mid H_{m,t} ) .
\end{equation}
We will refer to $P(Z_{m, t} \mid H_{m,t} )$ as the observation model for the $m$th model. We assume the observation model for each $m \in \mm$ is stationary with respect to $t$.

\subsection{Factorial hidden Markov model}

TODO
\begin{itemize}
\item note slightly different definition to Ghahramani and Jordan 1997.
\item be less vague about index set $\II$.
\end{itemize}

We consider factorial hidden Markov models consisting of a multiset of component hidden Markov models. We index the possible component HMMs in our factorial model using $i \in \II$. Let $m(i) \in \mm$ denote the component HMM associated with the $i$th index. We will represent a particular factorial model by the vector $(X_i)_{i \in \II}$, where each $X_i$ can be regarded as a random variable over the states $\{0, 1\}$. A value of $X_i=1$ indicates that the component HMM $m(i) \in \mm$ participates in the factorial model represented by $X = (X_i)_{i \in \II}$ .

Unlike the standard HMM situation where a single HMM with some hidden state is assumed to output a directly observable signal each time step, the factorial HMM assumes that the output of each HMM is not directly observable, but we are able to observe a signal $Y_t$ each $t \in \TT$ that aggregates contributions from the outputs of component models. We define this as the sum of the participating component signals:
\begin{equation}
Y_t = \sum_{i \in \II} X_i \event i t ,
\end{equation}
where we have introduced $\event i t = Z_{m(i), t}$. Note that there is no error term, errors can be modelled inside the $\event i t$ through the observation models of the component HMMs or alternatively by defining one or more component HMMs $m \in \mm$ to represent possible "error" signals.

\section{Inference}

TODO
\begin{itemize}
\item rework in terms of $i \in \II$.
\end{itemize}

Our goal is to infer a sparse subset of Markov processes that collectively explain the sequence of observations $Y$. Ideally we wish to estimate the posterior distribution $P(X | Y)$ of the activity parameter $X$. This is computationally challenging as it involves integrating over the states of all hidden trajectories $\{ \traj m\}_{m \in \mm}$ and potential hidden events $\{ Z_m \}_{m \in \mm}$. A much more tractable task is to instead compute a maximum a posteriori parameter estimate of the triple $(X, H, Z) = (X_m, \traj m, Z_m)_{m \in \mm}$ given the observed data $Y$.

To see why this is more tractable, consider the following factorisation of the conditional probability of the variables $X, H, Z$ given the data $Y$:
\begin{align}
P(X, H, Z \mid Y)
& = P(Y \mid X, H, Z) P(X, H, Z) / P(Y) \label{map1} \\
& \propto P(Y \mid X, H, Z) P(X, H, Z) \label{map2} \\
& = P(Y \mid X, Z) P(X, H, Z) \label{map3} \\
& = P(Y \mid X, Z) P(Z | X, H) P(X, H) \label{map4} \\
& = P\left(Y \mid X, Z\right) \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m} P(X, H) \label{map5} \\
& = P(Y = \sum_{m \in \mm} X_m \eventseq m \mid X, Z ) \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m} P(X, H) \label{map6}
\end{align}
where \ref{map1} uses Bayes' theorem, \ref{map2} drops the factor $P(Y)$ as it is invariant during maximisation over $(X, H, Z)$, \ref{map3} applies the conditional independence of $Y$ from $H$ given $X$ and $Z$, \ref{map5} is due to the conditional independence of the observation models given $Z$ implied by equation \ref{obsmodelindep}, and \ref{map6} applies the definition of $Y$.

To complete the decomposition of the conditional probability $P(H, H, Z \mid Y)$ in terms the distributions defined by the family of component Markov processes, we need to decide on $P(X, H)$, the prior for $X$ and $H$. We assume the prior probabilities of $\traj m$ and $\traj {m^{\prime}}$ are conditionally independent given $X$ for each distinct $m, m^{\prime} \in \mm$. Therefore we have
\begin{align}
P(X, H)
& = \prod_{m \in \mm} P(\traj m \mid X_m ) P(X) \\
& = \prod_{m \in \mm} P(\traj m)^{X_m} P(X)
\end{align}
where $P(\traj m)$ is the prior probability of the trajectory $\traj m$ of hidden states of the $m$th Markov process. We tentatively define a prior $P(X)$ over the bit vector $\{X_m\}_{m \in \mm} \in \{0, 1\}^{|\mm|}$ in terms of a prior $P(n)$ over the number of active processes $n = \sum_{m \in \mm} X_m$ that assigns higher prior probability to explanations involving fewer active Markov processes:
\begin{align}
P(X)
& = P(X \mid n) P(n) \\
& \propto \frac{1}{|\mm|^n \; 2^{n+1}}
\end{align}
where we have omitted a normalisation constant required so that $\sum_{X} P(X) = 1$

Consider the MAP parameter estimation problem:
\begin{equation}
(X^{\star}, H^{\star}, Z^{\star}) = \argmax_{X, H, Z} P\left(X, H, Z \mid Y\right)
\end{equation}
Substituting our decomposition of $P(X, H, Z | Y)$ and the definition of our prior $P(H, X)$ gives
\begin{align*}
& \argmax_{X, H, Z} P\left(X, H, Z \mid Y\right) \\
= & \argmax_{X, H, Z} P(Y = \sum_{m \in \mm} X_m \eventseq m \mid X, Z ) \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m} P(X, H) \\
= & \argmax_{X, H, Z} \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m}
\prod_{m \in \mm} P(\traj m)^{X_m}
\frac{1}{|\mm|^n \; 2^{n+1}} \\
 & \mathrm{s.t.} \sum_{m \in \mm} X_m \eventseq m = Y
\end{align*}
where $n = \sum_m X_m$ and the factor for the conditional probability of the observation vector $Y$ is equivalently expressed by the constraining the max to consider only those triples $(X, H, Z)$ such that $\sum_{m \in \mm} X_m \eventseq m = Y$.

We note that $\argmax$ is invariant under transformation of the objective function by a monotonic function, so by the monotonicity of the logarithm we have
\begin{align}
(X^{\star}, H^{\star}, Z^{\star})
= & \argmax_{X, H, Z} \sum_{m \in \mm} X_m C(\eventseq m, \traj m) \\
 & \mathrm{s.t.} \sum_{m \in \mm} X_m \eventseq m = Y ,
\end{align}
where $C(\eventseq m, \traj m)$ is defined by
\begin{equation*}
C(\eventseq m, \traj m) =
\log P\left(\eventseq m | \traj m\right) + 
\log P(\traj m) -
\left ( \log |\mm| + \log 2 \right) ,
\end{equation*}
and we have dropped terms from the $\argmax$ that are constant
with respect to $(X, H, Z)$.

% TODO change variables, prove equivalent to linear program

% TODO changing variables will allow multiple copies of a single
% class of Markov process to appear in the solution. That's fine.
% it'd be cleaner to rework notation so this is possible from
% the beginning. Let x select 0, 1 or many copies of each m
% instead of writing X_m write m(X) for how many copies of m
% are in X ?

% TODO fixup notation, use Z^(m) not Z_(m) for consistency

% TODO bibiliography

\end{document}
