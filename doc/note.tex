\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}

\newcommand{\xx}[0] {\mathbb{X}} % model space
\newcommand{\hh}[0] {\mathbb{H}} % model space
\newcommand{\zz}[0] {\mathbb{Z}} % model space
\newcommand{\mm}[0] {\mathbb{M}} % model space
\newcommand{\traj}[1] {H^{(#1)}}
\newcommand{\state}[2] {H_{#2}^{(#1)}}
\newcommand{\event}[2] {Z_{#2}^{(#1)}}
\newcommand{\eventseq}[1] {Z_{(#1)}}
\newcommand{\reals}[0] {\mathbb{R}}
\newcommand{\naturals}[0] {\mathbb{N}}
\newcommand{\events}[0] {\mathbb{Y}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}
Let $\{ \traj m \}_m$ be a family of possible trajectories of first-order Markov processes, indexed by $m \in \mm$. For each $m \in \mm$ let $S_m = \{s_1, \ldots, s_{K^{(m)}}\}$, $K^{(m)} \in \naturals$, denote the finite state space of hidden states that the $m$th Markov process transitions between. The state of each trajectory $\traj m$ is defined as the vector of hidden states over time: $\traj m = (\state m 1, \ldots \state m T)$, where each $\state m t \in S_m$.

We assume that although the family of possible Markov processes $\{\traj m\}_{m \in \mm}$ may be very large, only a sparse subset of processes are active and contribute indirectly toward observable events. Let $X = \{X_m\}_{m \in \mm}$ denote a vector of binary variables $X_m \in \{0, 1\}$, with the interpretation that $\traj m$ is active iff $X_m = 1$. We assume $X$ is stationary, that is, the set of active processes $\{ \traj m : X_m = 1\}_{m \in \mm}$ does not vary with respect to time $t$.

At each $t \in T$ the $m$th Markov process emits an event $\event m t \ \in \events$, where the space of events, $\events$, is a vector space over $\reals$. These events emitted by specific Markov processes are not directly observable, like the state of the generating Markov processes the events are also hidden variables. Each Markov process defines an observation model where the conditional probability of emitting an event depends only upon the current hidden state of that process:
\begin{equation}
P\left(\event m t = z \mid \{\state {m^\prime} s\}_{m^\prime \in \mm, s \in T} \right) =
P\left(\event m t = z \mid \state m t \right) \label{obsmodelindep}
\end{equation}

At each time $t \in T$ we observe some event $Y_t \in \events$ that aggregates contributions from each hidden event $\event m t$ generated by the active set Markov processes $\{ \traj m : X_m = 1\}_{m \in \mm}$. Let $Y$ denote the sequence of observations $\{Y_t\}_t$ indexed over time $t \in T$, where each element is given by
\begin{equation}
Y_t = \sum_{m \in \mm} X_m \event m t .
\end{equation}

Our goal is to infer a sparse subset of Markov processes that collectively explain the sequence of observations $Y$. Ideally we wish to estimate the posterior distribution $P(X | Y)$ of the activity parameter $X$. This is computationally challenging as it involves integrating over the states of all hidden trajectories $\{ \traj m\}_{m \in \mm}$ and potential hidden events $\{ Z_m \}_{m \in \mm}$. A much more tractable task is to instead compute a maximum a posteriori parameter estimate of the triple $(X, H, Z) = (X_m, \traj m, Z_m)_{m \in \mm}$ given the observed data $Y$.

To see why this is more tractable, consider the following factorisation of the conditional probability of the variables $X, H, Z$ given the data $Y$:
\begin{align}
P(X, H, Z \mid Y)
& = P(Y \mid X, H, Z) P(X, H, Z) / P(Y) \label{map1} \\
& \propto P(Y \mid X, H, Z) P(X, H, Z) \label{map2} \\
& = P(Y \mid X, Z) P(X, H, Z) \label{map3} \\
& = P(Y \mid X, Z) P(Z | X, H) P(X, H) \label{map4} \\
& = P\left(Y \mid X, Z\right) \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m} P(X, H) \label{map5} \\
& = P(Y = \sum_{m \in \mm} X_m \eventseq m \mid X, Z ) \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m} P(X, H) \label{map6}
\end{align}
where \ref{map1} uses Bayes' theorem, \ref{map2} drops the factor $P(Y)$ as it is invariant during maximisation over $(X, H, Z)$, \ref{map3} applies the conditional independence of $Y$ from $H$ given $X$ and $Z$, \ref{map5} is due to the conditional independence of the observation models given $Z$ implied by equation \ref{obsmodelindep}, and \ref{map6} applies the definition of $Y$.

To complete the decomposition of the conditional probability $P(H, H, Z \mid Y)$ in terms the distributions defined by the family of component Markov processes, we need to decide on $P(X, H)$, the prior for $X$ and $H$. We assume the prior probabilities of $\traj m$ and $\traj {m^{\prime}}$ are conditionally independent given $X$ for each distinct $m, m^{\prime} \in \mm$. Therefore we have
\begin{align}
P(X, H)
& = \prod_{m \in \mm} P(\traj m \mid X_m ) P(X) \\
& = \prod_{m \in \mm} P(\traj m)^{X_m} P(X)
\end{align}
where $P(\traj m)$ is the prior probability of the trajectory $\traj m$ of hidden states of the $m$th Markov process. We tentatively define a prior $P(X)$ over the bit vector $\{X_m\}_{m \in \mm} \in \{0, 1\}^{|\mm|}$ in terms of a prior $P(n)$ over the number of active processes $n = \sum_{m \in \mm} X_m$ that assigns higher prior probability to explanations involving fewer active Markov processes:
\begin{align}
P(X)
& = P(X \mid n) P(n) \\
& \propto \frac{1}{|\mm|^n \; 2^{n+1}}
\end{align}
where we have omitted a normalisation constant required so that $\sum_{X} P(X) = 1$

Consider the MAP parameter estimation problem:
\begin{equation}
(X^{\star}, H^{\star}, Z^{\star}) = \argmax_{X, H, Z} P\left(X, H, Z \mid Y\right)
\end{equation}
Substituting our decomposition of $P(X, H, Z | Y)$ and the definition of our prior $P(H, X)$ gives
\begin{align*}
& \argmax_{X, H, Z} P\left(X, H, Z \mid Y\right) \\
= & \argmax_{X, H, Z} P(Y = \sum_{m \in \mm} X_m \eventseq m \mid X, Z ) \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m} P(X, H) \\
= & \argmax_{X, H, Z} \prod_{m \in \mm} P\left(\eventseq m | \traj m\right)^{X_m}
\prod_{m \in \mm} P(\traj m)^{X_m}
\frac{1}{|\mm|^n \; 2^{n+1}} \\
 & \mathrm{s.t.} \sum_{m \in \mm} X_m \eventseq m = Y
\end{align*}
where $n = \sum_m X_m$ and the factor for the conditional probability of the observation vector $Y$ is equivalently expressed by the constraining the max to consider only those triples $(X, H, Z)$ such that $\sum_{m \in \mm} X_m \eventseq m = Y$.

We note that $\argmax$ is invariant under transformation of the objective function by a monotonic function, so by the monotonicity of the logarithm we have
\begin{align}
(X^{\star}, H^{\star}, Z^{\star})
= & \argmax_{X, H, Z} \sum_{m \in \mm} X_m C(\eventseq m, \traj m) \\
 & \mathrm{s.t.} \sum_{m \in \mm} X_m \eventseq m = Y ,
\end{align}
where $C(\eventseq m, \traj m)$ is defined by
\begin{equation*}
C(\eventseq m, \traj m) =
\log P\left(\eventseq m | \traj m\right) + 
\log P(\traj m) -
\left ( \log |\mm| + \log 2 \right) ,
\end{equation*}
and we have dropped terms from the $\argmax$ that are constant
with respect to $(X, H, Z)$.

% TODO change variables, prove equivalent to linear program

% TODO changing variables will allow multiple copies of a single
% class of Markov process to appear in the solution. That's fine.
% it'd be cleaner to rework notation so this is possible from
% the beginning. Let x select 0, 1 or many copies of each m
% instead of writing X_m write m(X) for how many copies of m
% are in X ?

% TODO fixup notation, use Z^(m) not Z_(m) for consistency

\end{document}
